{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rJcmnVyU2Ht"
      },
      "source": [
        "# Basic Lhotse Workflow\n",
        "\n",
        "This notebook shows how to write a dataloading pipeline for ASR using mini LibriSpeech dataset, so that the download is quick.\n",
        "\n",
        "We don't pre-compute the features here for simplicity; in real workflows you might want to precompute them if your disks are slow to read. We will demonstrate that in a separate tutorial.\n",
        "\n",
        "Optionally, uncomment the cells that download RIRs and MUSAN data to enable on-the-fly RIR reverberation and additive noise."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "is_executing": true,
          "name": "#%%\n"
        },
        "id": "7K78pKJJU2Hu"
      },
      "outputs": [],
      "source": [
        "# Optional auto-formatting\n",
        "\n",
        "!pip install nb_black\n",
        "%load_ext lab_black"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sHJEkQ6iU2Hv"
      },
      "outputs": [],
      "source": [
        "# Get the latest version of Lhotse, if not installed:\n",
        "\n",
        "!pip install git+https://github.com/lhotse-speech/lhotse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QivvOHaAU2Hv"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from concurrent.futures import ProcessPoolExecutor\n",
        "from pathlib import Path\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from lhotse import CutSet, Fbank, RecordingSet\n",
        "from lhotse.dataset import (\n",
        "    CutMix,\n",
        "    DynamicBucketingSampler,\n",
        "    K2SpeechRecognitionDataset,\n",
        "    OnTheFlyFeatures,\n",
        "    PerturbSpeed,\n",
        "    PerturbVolume,\n",
        "    RandomizedSmoothing,\n",
        "    ReverbWithImpulseResponse,\n",
        "    SpecAugment,\n",
        ")\n",
        "from lhotse.recipes import (\n",
        "    download_librispeech,\n",
        "    download_musan,\n",
        "    download_rir_noise,\n",
        "    prepare_librispeech,\n",
        "    prepare_musan,\n",
        "    prepare_rir_noise,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WW1_yG3bU2Hv"
      },
      "outputs": [],
      "source": [
        "root_dir = Path(\"data\")\n",
        "num_jobs = os.cpu_count() - 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLPokDfUU2Hw"
      },
      "source": [
        "# (mini) LibriSpeech\n",
        "\n",
        "We're downloading the data, preparing recording/supervision manfiests, and compiling them into CutSets.\n",
        "A cut is a basic \"example\" of data in Lhotse.\n",
        "\n",
        "Approx. download size 450MB."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O5FQtjZRU2Hw"
      },
      "outputs": [],
      "source": [
        "# libri_variant = \"librispeech\"\n",
        "libri_variant = \"mini_librispeech\"\n",
        "libri_root = download_librispeech(root_dir, dataset_parts=libri_variant)\n",
        "libri = prepare_librispeech(\n",
        "    libri_root, dataset_parts=libri_variant, output_dir=root_dir, num_jobs=num_jobs\n",
        ")\n",
        "cuts_train = CutSet.from_manifests(**libri[\"train-clean-5\"]).trim_to_supervisions()\n",
        "cuts_dev = CutSet.from_manifests(**libri[\"dev-clean-2\"]).trim_to_supervisions()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ooZ6Tu-U2Hx"
      },
      "source": [
        "# [Optional] Room impulse responses for reverb\n",
        "\n",
        "Uncomment to enable reverberation in training dataloader (approx. download size 1GB)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cyr5nuFxU2Hx"
      },
      "outputs": [],
      "source": [
        "rir_recordings = RecordingSet()\n",
        "# rir_raw_dir = download_rir_noise(root_dir)\n",
        "# rirs = prepare_rir_noise(rir_raw_dir, output_dir=root_dir, parts=[\"sim_rir\"])\n",
        "# rir_recordings = rirs[\"sim_rir\"][\"recordings\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUNVOfYTU2Hx"
      },
      "source": [
        "# [Optional] MUSAN for noise augmentation\n",
        "\n",
        "Uncomment to enable additive noise in training dataloader (approx. download size 10GB)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vyZ08dcLU2Hy"
      },
      "outputs": [],
      "source": [
        "musan_cuts = CutSet()\n",
        "# musan_raw_dir = download_musan(root_dir)\n",
        "# musan = prepare_musan(musan_raw_dir, output_dir=root_dir)\n",
        "# musan_cuts = CutSet.from_manifests(\n",
        "#     recordings=(\n",
        "#         musan[\"music\"][\"recordings\"]\n",
        "#         + musan[\"noise\"][\"recordings\"]\n",
        "#         + musan[\"speech\"][\"recordings\"]\n",
        "#     )\n",
        "# )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRTnchUiU2Hy"
      },
      "source": [
        "# Training DataLoader\n",
        "\n",
        "Training DataLoader consists of two main classes.\n",
        "Sampler decides how examples are put together into batches.\n",
        "Dataset convert a mini-batch of cuts (meta-data) into a dictionary of tensors used for training.\n",
        "You can find more details at: https://lhotse.readthedocs.io/en/latest/datasets.html\n",
        "\n",
        "In this example we use a `K2SpeechRecognitionDataset` for k2-specific ASR, which can be customized with augmentation transforms. For your own applications, you may want to write your own dataset class, but all of the other components should work for you without modifications.\n",
        "\n",
        "To see actual recipes of training ASR with k2 and Lhotse, visit https://github.com/k2-fsa/icefall\n",
        "\n",
        "The dataloader's batch_size has to be set to None since we already performed batching in the sampler."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4gkdsPo2U2Hy"
      },
      "outputs": [],
      "source": [
        "# Training dataset has augmentations\n",
        "train_sampler = DynamicBucketingSampler(\n",
        "    cuts_train,\n",
        "    shuffle=True,\n",
        "    max_duration=100.0,\n",
        "    num_buckets=10,\n",
        ")\n",
        "\n",
        "train_dataset = K2SpeechRecognitionDataset(\n",
        "    cut_transforms=[\n",
        "        PerturbSpeed(factors=[0.9, 1.1], p=2 / 3),\n",
        "        PerturbVolume(scale_low=0.125, scale_high=2.0, p=0.5),\n",
        "        # [optional] you can supply noise examples to be mixed in the data\n",
        "        CutMix(musan_cuts, snr=[10, 20], p=0.5),\n",
        "        # [optional] you can supply RIR examples to reverberate the data\n",
        "        ReverbWithImpulseResponse(rir_recordings, p=0.5),\n",
        "    ],\n",
        "    input_transforms=[\n",
        "        SpecAugment(),  # default configuration is well-tuned\n",
        "    ],\n",
        "    input_strategy=OnTheFlyFeatures(Fbank()),\n",
        ")\n",
        "\n",
        "train_dloader = DataLoader(\n",
        "    train_dataset,\n",
        "    sampler=train_sampler,\n",
        "    batch_size=None,\n",
        "    num_workers=0,  # For faster dataloading, use num_workers > 1\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2BlA2hPU2Hy"
      },
      "source": [
        "### High-level architecture of the solution\n",
        "\n",
        "```\n",
        "┌────────────────────────────────────────────────────────────────────────┐\n",
        "│┌──────────────────────────────────────────────────────────────────────┐│\n",
        "││                            Training loop                             ││\n",
        "│└──────────────────────────────────────────────────────────────────────┘│\n",
        "│                                                    │                   │\n",
        "│                                                    ▼                   │\n",
        "│                                 ┌────────────────────────────────────┐ │\n",
        "│ ┌───────────┐   ┌───────────┐   │    torch.utils.data.DataLoader     │ │\n",
        "│ │  CutSet   │◀──│  Sampler  │◀──│  (round-robin mini-batch CutSets   │ │\n",
        "│ └───────────┘   └───────────┘   │  from the sampler to the workers)  │ │\n",
        "│                                 └────────────────────────────────────┘ │\n",
        "└────────────────────────────────────────────────────┬───────────────────┘\n",
        "      ┌──────────────┬───────────────────────────────┴──────────────┐     \n",
        "      │              │                                              │     \n",
        "      ▼       ┌──────▼──────────────────────────────────────┐       ▼     \n",
        " ┌─────────┐  │  ┌─────────┐                 Sub-process #i │  ┌─────────┐\n",
        " │Worker #1│  │  │Worker #i│─────┐      ┌─────────────────┐ │  │Worker #N│\n",
        " └─────────┘  │  └─────────┘     │      │Map-style Dataset│ │  └─────────┘\n",
        "              │                  └─────▶│ (task-specific) │ │             \n",
        "              │                         └─────────────────┘ │             \n",
        "              └─────────────────────────────────────────────┘             \n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38_EzBZJU2Hz"
      },
      "source": [
        "### Visualisation\n",
        "\n",
        "Notice that the training mini-batch examples are perturbed in different ways, e.g. masking from SpecAugment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RkIuAdbOU2Hz"
      },
      "outputs": [],
      "source": [
        "from lhotse.dataset.vis import plot_batch\n",
        "\n",
        "for batch in train_dloader:\n",
        "    plot_batch(batch)\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBF7LhWuU2Hz"
      },
      "source": [
        "# Dev DataLoader\n",
        "\n",
        "For dev data, we don't want to use any augmentations, so we create another dataset that doesn't have them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ePVG0xZHU2Hz"
      },
      "outputs": [],
      "source": [
        "# Dev dataset doesn't have any augmentation\n",
        "dev_dataset = K2SpeechRecognitionDataset(\n",
        "    input_strategy=OnTheFlyFeatures(Fbank()),\n",
        ")\n",
        "dev_sampler = DynamicBucketingSampler(\n",
        "    cuts_dev, shuffle=False, max_duration=100.0, num_buckets=5\n",
        ")\n",
        "dev_dloader = DataLoader(\n",
        "    dev_dataset,\n",
        "    sampler=dev_sampler,\n",
        "    batch_size=None,\n",
        "    num_workers=0,  # For faster dataloading, use num_workers > 1\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KdBKMRfSU2H0"
      },
      "source": [
        "### Visualisation\n",
        "\n",
        "Notice that the training mini-batch examples are perturbed in different ways, e.g. masking from SpecAugment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4P4BRo3kU2H0"
      },
      "outputs": [],
      "source": [
        "from lhotse.dataset.vis import plot_batch\n",
        "\n",
        "for batch in dev_dloader:\n",
        "    plot_batch(batch)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ttnfwYgyU2H0"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}